概要

承知いたしました。提供されたソースとこれまでの会話履歴に基づき、「DeepStack: Expert-level artificial intelligence in heads-up no-limit poker」論文の概要を説明します。
この論文は、不完全情報ゲームにおける人工知能（AI）の重要なブレークスルーであるDeepStackというアルゴリズムについて述べています。過去20年間、AIはバックギャモン、チェッカー、チェス、Goといった完全情報ゲームで人間の専門家を超えるパフォーマンスを達成してきましたが、ポーカーのようなプレイヤーが非対称な情報を持つ不完全情報ゲームはAIにとって長年の課題でした。特に、ヘッドアップノーリミットテキサスホールデム (HUNL) は、情報が非対称であり、決定点が10^160を超えるという膨大なゲームサイズを持つことから、非常に複雑な推論を必要とします。
DeepStackは、従来の抽象化ベースのアプローチとは根本的に異なる手法を採用しています。その主要な構成要素は以下の3つです:
1.
情報非対称性に対処するための再帰的推論。
2.
計算を関連する決定に集中させるための分解。
3.
ディープラーニングを用いて自己対局から自動的に学習される一種の直感（intuition）。
DeepStackの核心は、「継続的な再解決 (continual re-solving)」と呼ばれる、ゲーム全体を事前に解くのではなく、プレイヤーが行動する必要がある現在の公開状態における部分ゲームをその場で再解決する手法です。これにより、アルゴリズムはゲーム全体の戦略を維持する必要がなく、現在の状態に到達した際の自身の手札の確率分布（レンジ）と、相手の各手札に対する期待値（反実仮想価値、opponent counterfactual values）を追跡するだけで、理論的に健全な戦略を構築できるとされています。
再解決を実用的な計算時間で行うため、DeepStackは再解決する部分ゲームの深さを制限し（限定的な深さでの先読み、limited-depth look-ahead）、その先の計算を学習された価値関数で近似します。この価値関数は、あらゆるポーカーの状況と手札における価値を高速に見積もる「直感」として機能します。DeepStackでは、この学習された価値関数としてディープニューラルネットワークが使用されています。このネットワークは、ランダムに生成された多数のポーカー状況を解決して得られたデータを用いて訓練されます。
さらに、人間のプレイ速度に近づけるために、DeepStackは考慮するアクションの種類を限定し、疎な先読みツリーを構築します。これにより、再解決するゲームのサイズは約10^7の決定点にまで削減され、単一のGPUで5秒未満で解決可能になりました。
DeepStackは、理論的に健全であり、その限定的な深さでの継続的な再解決が十分な計算リソースと「良い」直感によってナッシュ均衡に任意に近似できることが示されています。
DeepStackの性能評価は、プロのポーカープレイヤーを相手に行った対戦によって行われました。評価には、分散の大きいポーカーの成績評価の精度を高めるためのAIVATという手法が用いられました。合計44,852ゲームの対戦の結果、DeepStackは統計的に有意な差でプロプレイヤーに勝利しました。全体で492 mbb/g（milli–big blinds per game）の勝利、AIVAT推定値では486 mbb/gという結果であり、プロプレイヤーが「かなりの差」と考える50 mbb/gを大きく上回るものでした。3000ゲームを完了した11人のプレイヤーのうち、DeepStackは10人に対して統計的に有意な勝利を収めました。
また、DeepStackの重要な目標であるExploitability（攻略されやすさ）の最小化についても評価されました。従来の抽象化ベースのプログラムがLocal Best Response (LBR) という手法で容易に攻略可能であったのに対し（例えば、いくつかのトッププログラムは750 mbb/gで常にフォールドするよりも大幅に攻略可能でした） [6, 29, Table 1]、LBRはDeepStackを全く攻略できず、逆にDeepStackに敗北したことが示されています [29, 31, Table 1]。これは、DeepStackの戦略が従来手法よりも大幅に攻略されにくいことを示唆しています。
結論として、DeepStackはHUNLにおいてプロプレイヤーレベルのパフォーマンスを達成し、不完全情報ゲームにおけるAIの新たなパラダイムを示しました。これは、情報非対称性を含む多くの現実世界の問題への応用にも示唆を与えるものです。

Introduction

はい、承知いたしました。ご提供いただいたソースとこれまでの会話履歴に基づき、「DeepStack: Expert-level artificial intelligence in heads-up no-limit poker」論文のIntroduction部分の日本語訳と解説を行います。
まず、Introduction部分と考えられるソース から の内容を日本語に訳します。その後、その内容について解説を加えます。
--------------------------------------------------------------------------------
DeepStack 論文 Introduction 部分の日本語訳
COMPUTER SCIENCE DeepStack: ヘッドアップノーリミットポーカーにおけるエキスパートレベルの人工知能 Matej Moravčík 他 人工知能は近年、いくつかのブレークスルーを遂げており、ゲームはしばしばそのマイルストーンとなってきました。これらのゲームに共通する特徴は、プレイヤーが完全な情報を持っているという点です。ポーカー、すなわち不完全情報ゲームの典型的なゲームは、人工知能における長年の挑戦課題でした。私たちは、不完全情報設定のためのアルゴリズムであるDeepStackを導入します。これは、情報非対称性を扱うための再帰的推論、計算を関連する決定に集中させるための分解、そしてディープラーニングを用いて自己対局から自動的に学習される一種の直感 を組み合わせています。44,000ハンドのポーカーを含む研究において、DeepStackはヘッドアップノーリミットテキサスホールデムにおいて、プロのポーカープレイヤーを統計的に有意な差で破りました。このアプローチは理論的に健全であり、従来のアプローチよりも Exploitable（攻略されやすい）戦略がより困難であることが示されています。
ゲームは長年にわたり、人工知能（AI）の進歩のベンチマークとして機能してきました。過去20年間で、コンピュータープログラムは、バックギャモン (1)、チェッカー (2)、チェス (3)、Jeopardy! (4)、Atariビデオゲーム (5)、Go (6) といったゲームで、人間のエキスパートプレイヤーを凌駕するパフォーマンスに到達しました。これらの成功はすべて、プレイヤーがゲームの現在の状態について同一の情報を持つ情報対称性、すなわち完全情報 のゲームに関わるものです。この完全情報という特性はまた、これらの成功を可能にしたアルゴリズム、例えばプレイ中の局所探索 (7, 8) の核心でもあります。
ゲーム理論の創始者であり計算のパイオニアであるジョン・フォン・ノイマンは、完全情報のないゲームでの推論を構想していました。「現実の人生はそうではない。現実の人生はブラフ、ちょっとした欺瞞の戦術、相手が自分が何をしようと考えているかをどう考えるかを自分自身に問うことから成り立っている。そしてそれが私の理論におけるゲームの本質である」 (9)。フォン・ノイマンが魅了されたゲームの一つがポーカーでした。ポーカーでは、プレイヤーには秘密のカードが配られ、最強のハンドを持っていると信じてベットしたりブラフしたり、相手のベットにコールしたり、あるいはフォールドしてそのハンドとすでポットに加えられたベットを諦めたりするターンが回ってきます。ポーカーは不完全情報ゲームであり、プレイヤーの秘密のカードがゲームの状態について彼らに非対称な情報 を与えます。ヘッドアップノーリミットテキサスホールデム (HUNL) は、ポーカーの2人対戦版です。
HUNLでは、最初に各プレイヤーに2枚のカードが伏せて配られ、その後の3回のラウンドで追加のカードが表向きに配られます。ベットのサイズに制限はありませんが、各ゲームで賭けられる合計金額には全体的な制限があります (10)。AI技術は、これまでにヘッドアップリミットテキサスホールデム のようなよりシンプルなゲームで成功を収めてきました。このゲームでは、すべてのベットが固定サイズであり、意思決定点 はわずか10^14未満です (11)。比較として、コンピューターはGo (6) で人間のエキスパートパフォーマンスを超えています。Goは完全情報ゲームであり、意思決定点は約10^170です (12)。不完全情報ゲームであるHUNLは、Goに匹敵する規模であり、意思決定点 は10^160を超えます (13)。
不完全情報ゲームは、同様の規模の完全情報ゲームよりも複雑な推論を必要とします。特定の瞬間の正しい決定は、相手が保持している秘密の情報に関する確率分布 に依存し、これは相手の過去の行動を通じて明らかになります。しかし、その情報が明らかになる方法は、相手が自分自身の秘密の情報について知っていること、そして自分の行動がそれをどのように明らかに するかに依存します。このような再帰的な推論 があるため、完全情報ゲームで使われるヒューリスティック探索手法 のように、ゲームの状況を個別に簡単に推論することはできません。不完全情報ゲームにおける競争力のあるAIアプローチは通常、プレイが始まる前にゲーム全体 を推論し、完全な戦略 を生成します (14–16)。Counterfactual Regret Minimization (CFR) (14, 17, 18) は、そのような手法の一つであり、プログラムは自己対局 を使用して、連続する反復の中で自身の戦略を調整することで再帰的な推論を行います。ゲームが大きすぎて直接解けない場合、一般的な対応策は、より小さな抽象化されたゲーム を解くことです。元のゲームをプレイするために、元のゲームの状況と行動を抽象化されたゲームに変換 します。このアプローチにより、プログラムがHUNLのようなゲームで推論することは可能になりますが、HUNLの10^160の状況を約10^14の抽象化された状況に圧縮することによってそうしています。
この情報損失 の結果として、そのようなプログラムは人間のエキスパートプレイに遅れをとっています。2015年、コンピュータープログラムClaudicoは、プロのポーカープレイヤーのチームに91 milli–big blinds per game (mbb/g) の差で敗北しました (19)。これは「巨大な勝利差」 (20) とされています。さらに、Annual Computer Poker Competitionの抽象化ベースのプログラムには、最近 massive flaws（重大な欠陥） があることが示されました (21)。そのようなプログラム4つ（2016年大会のトッププログラムを含む）は、戦略がどれだけ損をするかの近似的な下限を生成する local best response (LBR) 技術 を使用して評価されました。4つの抽象化ベースのプログラムすべてが、常にフォールドする 場合の750 mbb/gよりも大幅に、3000 mbb/g以上でBeat（攻略） 可能です (Table 1)。
DeepStackは根本的に異なるアプローチをとります。情報非対称性を扱うために、CFRの再帰的推論 を引き続き使用します。しかし、プレイ前に完全な戦略を計算・保存することはせず、したがって明示的な抽象化 を必要としません。代わりに、プレイ中に発生する各特定の状況 を考慮しますが、それらを個別に扱うわけではありません。特定の深さを超える計算を高速な近似推定 に置き換えることで、ゲームの残りの全体について推論することを避けます。この推定はDeepStackの直感、あらゆるポーカーの状況であらゆる可能な秘密のカードを持っていることの価値に関する直感的な感覚 と考えることができます。最後に、DeepStackの直感は、人間の直感とよく似て、訓練される必要があります。私たちはそれをディープラーニング (22) で訓練し、ランダムなポーカー状況から生成された例を使用します。私たちは、DeepStackが理論的に健全であり、抽象化ベースの手法よりも大幅に攻略が難しい戦略 を生成し、HUNLでプロのポーカープレイヤーを統計的に有意な差で破る ことを示します。
--------------------------------------------------------------------------------
Introduction 部分の解説
このIntroduction部分 (-) は、DeepStackという新しいAIアルゴリズムが、ヘッドアップノーリミットテキサスホールデム (HUNL) という非常に複雑な不完全情報ゲーム において、どのようにしてプロレベルのパフォーマンスを達成したのか、そしてそれが従来のAI研究手法とどう異なるのか を提示しています。
1.
ゲームとAIの進歩 AI研究において、ゲームは長らくベンチマークとして利用されてきました。過去20年間に、AIはバックギャモン、チェッカー、チェス、Goなど、完全情報ゲーム（プレイヤー全員がゲームの状態を完全に把握できるゲーム）において人間のエキスパートを超える成果を上げてきました。これらの成功は、ゲームの状態に基づいて探索を行うアルゴリズム に支えられています。
2.
不完全情報ゲームとしてのポーカーとHUNL しかし、現実世界は必ずしも完全情報ではありません。ジョン・フォン・ノイマンが指摘したように、現実のゲームにはブラフや欺瞞といった要素が伴います。ポーカーはまさにそのような不完全情報ゲーム の典型例です。プレイヤーは自分自身のプライベートな手札 しか完全に知らず、相手の手札は不明です。これが情報非対称性 を生み出します。 特に、HUNLはポーカーの中でも最も複雑な形式の一つです。2人対戦で、ベットサイズに制限がない（ノーリミット） ため、ゲームの進行パターンが爆発的に増大します。その意思決定点 は10^160を超え、完全情報ゲームのGo（約10^170）に匹敵する規模です。
3.
不完全情報ゲームの困難さと従来手法の限界 不完全情報ゲームでは、単にゲームの状態だけを見て最善手を打つわけにはいきません。相手の過去の行動から推測される相手の手札の確率分布 を考慮する必要があり、さらに相手が自分の行動をどう解釈するかという再帰的な推論 が求められます。これは完全情報ゲームで成功したヒューリスティック探索 をそのまま適用できない理由です。 従来、不完全情報ゲームのAIは、ゲームが始まる前にゲーム全体を解いて完全な戦略を事前に計算しておく アプローチが主流でした。ゲームが大きすぎる場合は、ゲームの状態やアクションをより少ない数に抽象化 することで計算量を削減していました。Counterfactual Regret Minimization (CFR) は、自己対局によって再帰的推論を行い、ナッシュ均衡戦略 を近似する強力な手法ですが、そのままではHUNLのような大規模ゲームには適用困難です。 しかし、この抽象化アプローチ は、情報損失 を招き、人間のプロレベルには及ばない 結果となっていました。例えば、Claudicoはプロに大差で敗れ (91 mbb/g)、さらに最近の評価では、抽象化ベースのトッププログラムですら、LBR（Local Best Response）という手法によって容易にExploit（攻略）可能 であり、常にフォールドするよりも大幅に弱い (3000 mbb/g以上の損失相当) ことが示されていました (Table 1)。AIがプロに勝つためには、単にそれなりに強いだけでなく、攻略されにくい戦略（Exploitabilityが低い戦略、ナッシュ均衡に近い戦略）をプレイする必要があるのです。
4.
DeepStackの革新的アプローチ DeepStackは、これらの課題に対して根本的に異なるアプローチ を提案しています。
◦
ゲーム全体を事前に解かない: DeepStackは、従来のようにゲーム全体を解いて完全な戦略をストアしません。代わりに、ゲーム中に実際に発生した特定の状況（公開状態）に焦点を当てて戦略を計算します。
◦
継続的な再解決 (Continual Re-solving): 行動が必要な現在の公開状態から始まる部分ゲーム を、その場で（オンザフライで）再解決 します。これにより、ゲーム全体の戦略を把握し続ける必要がなくなります。再解決のためには、自身の現在の手札の確率分布（レンジ） と、相手の各手札に対する期待値（反実仮想価値、counterfactual values） を追跡する必要があります。これは、情報非対称性に対処するための再帰的推論 の一環です。
◦
深さ制限と学習された価値関数: 再解決を実用的な時間で行うため、DeepStackは再解決する部分ゲームの深さを制限し、その先のゲームの価値を高速に推定する学習された価値関数 を使用します。この価値関数は、あらゆる状況と手札の価値を見積もる「直感」 として機能します。DeepStackでは、この「直感」 をディープニューラルネットワーク を用いて実装しています。このネットワークは、ランダムなポーカー状況を解決して得られたデータを使って自己対局 のように訓練されます。
◦
計算の集中（分解）: 上記の継続的な再解決 と深さ制限 は、計算を現在の関連する決定 に集中させる（ゲーム全体から部分ゲームへの分解） 効果があります。さらに、実用的なプレイ速度を達成するため、考慮するアクションの種類を限定し、疎な先読みツリー を構築します。これにより、再解決する部分ゲームのサイズは大幅に削減されます。
5.
理論的な健全性と実証 DeepStackのアプローチは、理論的に健全 であり、十分な計算資源と「良い」直感があれば、限定的な深さでの継続的な再解決がナッシュ均衡 に任意に近似できる ことが示されています (Theorem 1)。 そして、その性能はプロプレイヤーとの対戦で実証されました。44,000ハンド以上の対戦の結果、DeepStackはプロプレイヤーに対して統計的に有意な差 で勝利しました。その勝ち越し幅は492 mbb/g (AIVAT推定値では486 mbb/g) であり、プロが「かなりの差」 と考える50 mbb/g を大きく上回っています。また、LBRによるExploitabilityの評価 では、従来の抽象化ベースのプログラムが容易に攻略可能であったのに対し (Table 1)、LBRはDeepStackを全く攻略できず、DeepStackがLBRに勝利した ことは、DeepStackの戦略が従来手法よりも大幅に攻略されにくい ことを示唆しています。
要約すると、Introductionは、長年のAI研究の課題であった不完全情報ゲーム、特に膨大で複雑なHUNLにおいて、従来の抽象化と事前計算に頼る手法の限界を示し、DeepStackがその限界を打ち破るために採用した新しいパラダイム（継続的な再解決、深さ制限による部分ゲームの計算、学習された価値関数としてのディープラーニング） を提示しています。そして、このアプローチが理論的な健全性を持ちながら、実際にプロプレイヤーを破る ほどの強力なパフォーマンス と、従来のAIよりも低いExploitability を実現した ことを述べています。これは、不完全情報下のAI研究における重要なブレークスルーであると位置づけられています。